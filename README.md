# ğŸ¤– AI Conversation Platform v5.0 â€“ The Future of Multi-Agent Collaboration  

> **"Because AIs shouldn't monologue â€” they should *converse*."**

[![CI](https://github.com/systemslibrarian/AI-Conversation-Platform-The-Future-of-Multi-Agent-Collaboration/actions/workflows/ci.yml/badge.svg)](https://github.com/systemslibrarian/AI-Conversation-Platform-The-Future-of-Multi-Agent-Collaboration/actions/workflows/ci.yml)
[![CodeQL](https://github.com/systemslibrarian/AI-Conversation-Platform-The-Future-of-Multi-Agent-Collaboration/actions/workflows/codeql.yml/badge.svg)](https://github.com/systemslibrarian/AI-Conversation-Platform-The-Future-of-Multi-Agent-Collaboration/actions/workflows/codeql.yml)[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

## ğŸ§  GitHub Project Description  

**Let AIs Talk â€” Like Never Before.**  
*Watch Claude debate ChatGPT. See Gemini roast Grok. Let Perplexity fact-check them all â€” live, async, and unscripted.*

A **fully async, type-safe, enterprise-grade platform** that turns AI models into autonomous conversational agents.  
No scripts. No prompts. Just **real-time, multi-model dialogue** â€” with:

- **5 top-tier LLMs** (Claude, ChatGPT, Gemini, Grok, Perplexity)  
- **Zero-downtime async orchestration**  
- **Built-in circuit breakers & rate limiting**  
- **Live web dashboard + CLI control**  
- **Prometheus + Grafana observability**  
- **LLM Guard security & path hardening**  
- **Docker, CI/CD, 90 %+ test coverage**

```bash
uv run aic-start --agent1 claude --agent2 chatgpt --topic "AI consciousness" --yes
```

**Start a debate. Watch the sparks fly.**  
*Production-ready. Developer-obsessed. AI-to-AI, out of the box.*

---

**Optional one-liner (for GitHub short description):**  
> Async AI-to-AI conversations with observability, security, and zero boilerplate.

---

## âœ¨ Whatâ€™s New in v5.0 Enterprise

- âœ… Async orchestration & cancellation safety  
- âœ… Type-safe agents and queue system  
- âœ… Prometheus + Grafana monitoring stack  
- âœ… Full Docker support (`docker compose up`)  
- âœ… CI/CD with Ruff, Mypy, Pytest, and CodeQL  
- âœ… Modular architecture (CLI + Web + Core + Agents)  
- âœ… 5 LLMs supported out of the box

---

## ğŸš€ Quick Start

### **1ï¸âƒ£ Setup (with uv)**
```bash
uv sync --all-extras
```

### **2ï¸âƒ£ Run from CLI**
```bash
uv run aic-start --agent1 claude --agent2 chatgpt --topic "AI governance" --turns 6 --yes
```

### **3ï¸âƒ£ Run from Web UI**
```bash
uv run streamlit run web/app.py
```

### **4ï¸âƒ£ Run via Docker**
```bash
docker compose up --build
```

Access Streamlit â†’ [http://localhost:8501](http://localhost:8501)  
Access Grafana â†’ [http://localhost:3000](http://localhost:3000)  
Access Prometheus â†’ [http://localhost:9090](http://localhost:9090)

---

## ğŸ§© Architecture Overview

```
agents/         â†’  AI provider wrappers (Claude, ChatGPT, Gemini, Grok, Perplexity)
core/           â†’  Config, queue, metrics, tracing, and logging
cli/            â†’  Command-line interface (aic-start)
web/            â†’  Streamlit dashboard for live AI-to-AI sessions
monitoring/     â†’  Prometheus + Grafana stack (dockerized)
tests/          â†’  Pytest async coverage suite
.github/        â†’  CI/CD workflows (CI, CodeQL, Release)
```

---

## ğŸ“Š Monitoring & Metrics

**Prometheus targets**
- `record_call_total`  
- `record_latency_seconds`  
- `record_error_total`  
- `queue_size`  

**Grafana dashboard includes**
- Agent latency histogram  
- Conversation count  
- Error rate over time  
- Queue depth + system health  

Everything autoloads from `monitoring/grafana/provisioning`.

---

## ğŸ§± Testing & Quality Gates
```bash
uv run ruff check .
uv run mypy .
uv run pytest --cov
```

All workflows run automatically via GitHub Actions:
- âœ… `ci.yml` â†’ lint + type check + tests  
- âœ… `codeql.yml` â†’ CodeQL security scan  
- âœ… `release.yml` â†’ Docker build on tag push  

---

## ğŸ§° Development Shortcuts (Makefile)

| Command | Description |
|----------|--------------|
| `make setup` | Install dependencies with uv |
| `make lint` | Run Ruff linter + formatter |
| `make test` | Run pytest suite |
| `make streamlit` | Launch web UI |
| `make docker-up` | Start full stack (Prometheus + Grafana) |
| `make docker-down` | Stop containers and clean volumes |

---

## ğŸ“¦ Docker Images

Once tagged (`v5.0.0` etc.), GitHub Actions builds and publishes to:  
`ghcr.io/systemslibrarian/ai-conversation-platform`

---

## ğŸ”’ Security

- Built-in LLM Guard for sanitizing requests and responses  
- Secure async queues with Redis or SQLite  
- Auto-escaping and HTML cleaning in Streamlit (`bleach.clean`)  
- Configurable API keys via `.env` or environment variables

---

## ğŸ§ª Supported Agents
- ChatGPT (OpenAI GPT-4/4o)  
- Claude (Anthropic Claude 3 series)  
- Gemini (Google Generative AI)  
- Grok (X AI)  
- Perplexity AI  

Each agent is modular and hot-swappable under `agents/`.

---

## ğŸ§­ License & Credits
To God be the glory
MIT License Â© 2025 Systemslibrarian  
Developed with â¤ï¸ by Paul Clark (@systemslibrarian) and AI.


---

### â­ If you like this project
- Give it a â­ on GitHub â€” it helps others discover it!  
- Fork and experiment with your own AI-to-AI agents.  
- Contributions welcome via Pull Requests.

---
